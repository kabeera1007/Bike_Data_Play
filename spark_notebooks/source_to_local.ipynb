{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a1d8e-b4a5-4b23-99bd-af143ea42e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c402e80-a007-41fd-a6a5-0c03748d3bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401be34-ba65-48ea-8d90-e00b7b91d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88ebac-fee9-419a-b54e-5938a6493fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7514bc9-5eb3-4402-86d8-7aeaa1397833",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059a43c-1c8c-4ace-bfd8-aa95183c465f",
   "metadata": {},
   "source": [
    "** defining schema and reading data that was downloaded using **.sh scripts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e2765-6781-4a4a-8c14-9cf035f29b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/raw/divvy/*', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33aac0d-83c4-481e-967f-b677a4185648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec809f2a-dba0-4643-87b0-9a7a6d20ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5f807-4c2a-40a9-9073-46e8296a69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad9aeb-8393-4c2c-a166-4d1ca40d2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new schema\n",
    "new_schema = StructType([\n",
    "    StructField(\"ride_id\", StringType(), True),\n",
    "    StructField(\"rideable_type\", StringType(), True),\n",
    "    StructField(\"started_at\", TimestampType(), True),\n",
    "    StructField(\"ended_at\", TimestampType(), True),\n",
    "    StructField(\"start_station_name\", StringType(), True),\n",
    "    StructField(\"start_station_id\", StringType(), True),\n",
    "    StructField(\"end_station_name\", StringType(), True),\n",
    "    StructField(\"end_station_id\", StringType(), True),\n",
    "    StructField(\"start_lat\", FloatType(), True),\n",
    "    StructField(\"start_lng\", FloatType(), True),\n",
    "    StructField(\"end_lat\", FloatType(), True),\n",
    "    StructField(\"end_lng\", FloatType(), True),\n",
    "    StructField(\"member_casual\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27904e-6bca-495d-bca4-3991b31b5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file with the defined schema\n",
    "df = spark.read.schema(new_schema).csv('data/raw/divvy/*', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbae8e-e2de-4176-9054-fbdeb0b40354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the schema to verify\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6b50c-6d2c-4adc-a230-ec3b502dfd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.coalesce(1).write.parquet('data/taxi/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56949737-a977-4f13-845c-e43df7a7ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90098cc4-299d-431e-9b1f-090ae4e5eed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d63744-0ec0-4637-8384-963929f10b81",
   "metadata": {},
   "source": [
    "**dividing parquet to partitioned parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01114d97-298d-4f5c-826b-bc303a940ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "# Initialize Spark session with more memory\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PartitionTaxiData\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7dc0b2-3163-43d0-828b-2fc548e1d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the large Parquet file\n",
    "df = spark.read.parquet('data/taxi/part-00000-40d493c8-d381-4a07-9a71-39d7b190bb43-c000.snappy.parquet')\n",
    "\n",
    "# Add partition columns (adjust the column name as needed)\n",
    "df = df.withColumn('year', year('started_at'))  # Use 'started_at' as the timestamp column\n",
    "df = df.withColumn('month', month('started_at'))  # Use 'started_at' as the timestamp column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfbdc0-bbaf-4f78-9b7f-ceddfad10ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write partitioned data to a new folder\n",
    "df.write.partitionBy('year', 'month').parquet('data/taxi_partitioned',mode=\"overwrite\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517a99c-8309-44c9-a885-4c9070ac1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abab1293-0525-4c44-aec9-ff38614b0f91",
   "metadata": {},
   "source": [
    "**now reading from partioned parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24b281-be38-4ff0-b7ad-0b9381ddfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the partitioned data\n",
    "data = spark.read.parquet('data/taxi_partitioned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fae56e-cf22-4a86-881a-8bc77f238ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12566e-607a-4e20-8181-4cee0c62afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('member_casual').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefee74-d5ca-4971-8802-d1e0b9e3615e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
